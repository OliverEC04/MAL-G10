{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a3a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "IMG_SIZE = 512\n",
    "\n",
    "def load_images_from_folder(folder_path, label, img_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        img = load_img(img_path, target_size=(img_size, img_size))\n",
    "        img_array = img_to_array(img) / 255.0\n",
    "        data.append(img_array)\n",
    "        labels.append(label)\n",
    "    return data, labels\n",
    "\n",
    "# Load training data\n",
    "train_is_path = \"ice_cream/train/ice_cream\"\n",
    "train_not_path = \"ice_cream/train/non_ice_cream\"\n",
    "train_data_is, labels_is = load_images_from_folder(train_is_path, 1, IMG_SIZE)\n",
    "train_data_not, labels_not = load_images_from_folder(train_not_path, 0, IMG_SIZE)\n",
    "\n",
    "X_train = np.array(train_data_is + train_data_not)\n",
    "y_train = np.array(labels_is + labels_not)\n",
    "\n",
    "# Load testing data\n",
    "test_is_path = \"ice_cream/test/ice_cream\"\n",
    "test_not_path = \"ice_cream/test/non_ice_cream\"\n",
    "test_data_is, test_labels_is = load_images_from_folder(test_is_path, 1, IMG_SIZE)\n",
    "test_data_not, test_labels_not = load_images_from_folder(test_not_path, 0, IMG_SIZE)\n",
    "\n",
    "X_test = np.array(test_data_is + test_data_not)\n",
    "y_test = np.array(test_labels_is + test_labels_not)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f40521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shapes:\n",
      "x_train: (1800, 512, 512, 3) | y_train: (1800,)\n",
      "x_test: (200, 512, 512, 3) | y_test: (200,)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hassa\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n",
      "Epoch 1/30\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 4s/step - accuracy: 0.5454 - loss: 1.3397 - precision: 0.5315 - recall: 0.4835 - val_accuracy: 0.7550 - val_loss: 0.5967 - val_precision: 0.7742 - val_recall: 0.7200\n",
      "Epoch 2/30\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 3s/step - accuracy: 0.7036 - loss: 0.5848 - precision: 0.7353 - recall: 0.6568 - val_accuracy: 0.7650 - val_loss: 0.5714 - val_precision: 0.7912 - val_recall: 0.7200\n",
      "Epoch 3/30\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 4s/step - accuracy: 0.7190 - loss: 0.5586 - precision: 0.7315 - recall: 0.7165 - val_accuracy: 0.7800 - val_loss: 0.5508 - val_precision: 0.7456 - val_recall: 0.8500\n",
      "Epoch 4/30\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 3s/step - accuracy: 0.7264 - loss: 0.5338 - precision: 0.7165 - recall: 0.7408 - val_accuracy: 0.7950 - val_loss: 0.5480 - val_precision: 0.7864 - val_recall: 0.8100\n",
      "Epoch 5/30\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 3s/step - accuracy: 0.7269 - loss: 0.5428 - precision: 0.7639 - recall: 0.6803 - val_accuracy: 0.7850 - val_loss: 0.5396 - val_precision: 0.8065 - val_recall: 0.7500\n",
      "Epoch 6/30\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 3s/step - accuracy: 0.7387 - loss: 0.5184 - precision: 0.7686 - recall: 0.6934 - val_accuracy: 0.8200 - val_loss: 0.5058 - val_precision: 0.8265 - val_recall: 0.8100\n",
      "Epoch 7/30\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 3s/step - accuracy: 0.7794 - loss: 0.4834 - precision: 0.7909 - recall: 0.7722 - val_accuracy: 0.8100 - val_loss: 0.5092 - val_precision: 0.8039 - val_recall: 0.8200\n",
      "Epoch 8/30\n",
      "\u001b[1m31/57\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:04\u001b[0m 5s/step - accuracy: 0.7850 - loss: 0.4593 - precision: 0.7689 - recall: 0.7877"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data information\n",
    "print(\"Data Shapes:\")\n",
    "print(f\"x_train: {X_train.shape} | y_train: {y_train.shape}\")\n",
    "print(f\"x_test: {X_test.shape} | y_test: {y_test.shape}\\n\")\n",
    "\n",
    "# Shuffle data\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=42)\n",
    "\n",
    "# Enhanced CNN model with regularization\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.2),  # Added dropout for regularization\n",
    "    \n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),  # Increased dropout\n",
    "    \n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),  # Added more filters\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),  # Increased units\n",
    "    layers.Dropout(0.5),  # Higher dropout for dense layer\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile with lower learning rate\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train model with validation\n",
    "print(\"Training model...\\n\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=30,  # Increased epochs\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nModel Evaluation:\")\n",
    "test_loss, test_acc, test_precision, test_recall = model.evaluate(X_test, y_test)\n",
    "test_f1 = 2 * (test_precision * test_recall) / (test_precision + test_recall)\n",
    "\n",
    "print(f'\\nTest accuracy: {test_acc:.4f}')\n",
    "print(f'Test precision: {test_precision:.4f}')\n",
    "print(f'Test recall: {test_recall:.4f}')\n",
    "print(f'Test F1-score: {test_f1:.4f}')\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = (y_pred > 0.5).astype(\"int32\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes, \n",
    "                          target_names=['Not Ice Cream', 'Ice Cream']))\n",
    "\n",
    "# Enhanced confusion matrix plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "conf_mat = confusion_matrix(y_test, y_pred_classes)\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Not Ice Cream', 'Ice Cream'],\n",
    "            yticklabels=['Not Ice Cream', 'Ice Cream'],\n",
    "            annot_kws={\"size\": 14})\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.ylabel('True Label', fontsize=14)\n",
    "plt.xlabel('Predicted Label', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Enhanced training history plots\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "plt.plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "plt.title('Model Accuracy', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "plt.title('Model Loss', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "model.save('ice_cream_classifier_improved.h5')\n",
    "print(\"\\nModel saved as 'ice_cream_classifier_improved.h5'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
