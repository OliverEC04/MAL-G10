{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a3a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "IMG_SIZE = 512\n",
    "\n",
    "def load_images_from_folder(folder_path, label, img_size):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for img_name in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        img = load_img(img_path, target_size=(img_size, img_size))\n",
    "        img_array = img_to_array(img) / 255.0\n",
    "        data.append(img_array)\n",
    "        labels.append(label)\n",
    "    return data, labels\n",
    "\n",
    "# Load training data\n",
    "train_is_path = \"ice_cream/train/ice_cream\"\n",
    "train_not_path = \"ice_cream/train/non_ice_cream\"\n",
    "train_data_is, labels_is = load_images_from_folder(train_is_path, 1, IMG_SIZE)\n",
    "train_data_not, labels_not = load_images_from_folder(train_not_path, 0, IMG_SIZE)\n",
    "\n",
    "X_train = np.array(train_data_is + train_data_not)\n",
    "y_train = np.array(labels_is + labels_not)\n",
    "\n",
    "# Load testing data\n",
    "test_is_path = \"ice_cream/test/ice_cream\"\n",
    "test_not_path = \"ice_cream/test/non_ice_cream\"\n",
    "test_data_is, test_labels_is = load_images_from_folder(test_is_path, 1, IMG_SIZE)\n",
    "test_data_not, test_labels_not = load_images_from_folder(test_not_path, 0, IMG_SIZE)\n",
    "\n",
    "X_test = np.array(test_data_is + test_data_not)\n",
    "y_test = np.array(test_labels_is + test_labels_not)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f40521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test:  (200, 512, 512, 3)\n",
      "y_test:  (200,)\n",
      "x_train:  (1800, 512, 512, 3)\n",
      "y_train:  (1800,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\morte\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You must call `compile()` before using the model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m64\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))  \u001b[38;5;66;03m# Binær classification (is / not-is)\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test))\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     27\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# also hvad pokker er det her\u001b[39;00m\n\u001b[0;32m     28\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32mc:\\Users\\morte\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\morte\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py:1049\u001b[0m, in \u001b[0;36mTrainer._assert_compile_called\u001b[1;34m(self, method_name)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1048\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalling `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1049\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: You must call `compile()` before using the model."
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Træning:\n",
    "print(\"x_test: \", X_test.shape)\n",
    "print(\"y_test: \", y_test.shape)\n",
    "print(\"x_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "\n",
    "# Shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "X_test, y_test = shuffle(X_test, y_test, random_state=42)\n",
    "\n",
    "\n",
    "# CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))  # Binær classification (is / not-is)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy', # also hvad pokker er det her\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# # laver om til numpy arrays\n",
    "# X_train = np.array(training_data)\n",
    "# X_test = np.array(test_data)\n",
    "\n",
    "# # labels labels labels\n",
    "# y_train = np.ones(len(X_train))     # 1 = is\n",
    "# y_test = np.zeros(len(X_test))      # 0 = ikke-is\n",
    "\n",
    "# # CNN model\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))  # Binær classification (is / not-is)\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='binary_crossentropy', # also hvad pokker er det her\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# # # vi normaliserer dataen til at være mellem 0 og 1\n",
    "# # training_data = [img / 512 for img in training_data]\n",
    "\n",
    "# # test_data = [img / 512 for img in test_data]\n",
    "\n",
    "# # # Normalize the images to the range of 0 to 1\n",
    "# # train_images = train_images.astype('float32') / 255.0\n",
    "# # test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# # # vi henter en CNN model fra keras:\n",
    "# # from tensorflow.keras import layers, models\n",
    "# # model = models.Sequential()\n",
    "# # model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(512, 512, 3)))\n",
    "# # model.add(layers.MaxPooling2D((2, 2)))\n",
    "# # model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "# # model.add(layers.MaxPooling2D((2, 2)))\n",
    "# # model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
