{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75a3a250",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "IMG_SIZE = 512\n",
        "\n",
        "def load_images_from_folder(folder_path, label, img_size):\n",
        "    data = []\n",
        "    labels = []\n",
        "    for img_name in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img_name)\n",
        "        img = load_img(img_path, target_size=(img_size, img_size))\n",
        "        img_array = img_to_array(img) / 255.0\n",
        "        data.append(img_array)\n",
        "        labels.append(label)\n",
        "    return data, labels\n",
        "\n",
        "# training data\n",
        "train_is_path = \"ice_cream/train/ice_cream\"\n",
        "train_not_path = \"ice_cream/train/non_ice_cream\"\n",
        "train_data_is, labels_is = load_images_from_folder(train_is_path, 1, IMG_SIZE)\n",
        "train_data_not, labels_not = load_images_from_folder(train_not_path, 0, IMG_SIZE)\n",
        "\n",
        "X_train = np.array(train_data_is + train_data_not)\n",
        "y_train = np.array(labels_is + labels_not)\n",
        "\n",
        "# testing data\n",
        "test_is_path = \"ice_cream/test/ice_cream\"\n",
        "test_not_path = \"ice_cream/test/non_ice_cream\"\n",
        "test_data_is, test_labels_is = load_images_from_folder(test_is_path, 1, IMG_SIZE)\n",
        "test_data_not, test_labels_not = load_images_from_folder(test_not_path, 0, IMG_SIZE)\n",
        "\n",
        "X_test = np.array(test_data_is + test_data_not)\n",
        "y_test = np.array(test_labels_is + test_labels_not)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e018faa7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK(function setup)\n"
          ]
        }
      ],
      "source": [
        "# Rapport generator funktioner\n",
        "from time import time\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn import datasets\n",
        "\n",
        "# from libitmal import dataloaders as itmaldataloaders # Needed for load of iris, moon and mnist\n",
        "\n",
        "currmode=\"N/A\" # GLOBAL var!\n",
        "\n",
        "def SearchReport(model): \n",
        "    \n",
        "    def GetBestModelCTOR(model, best_params):\n",
        "        def GetParams(best_params):\n",
        "            ret_str=\"\"          \n",
        "            for key in sorted(best_params):\n",
        "                value = best_params[key]\n",
        "                temp_str = \"'\" if str(type(value))==\"<class 'str'>\" else \"\"\n",
        "                if len(ret_str)>0:\n",
        "                    ret_str += ','\n",
        "                ret_str += f'{key}={temp_str}{value}{temp_str}'  \n",
        "            return ret_str          \n",
        "        try:\n",
        "            param_str = GetParams(best_params)\n",
        "            return type(model).__name__ + '(' + param_str + ')' \n",
        "        except:\n",
        "            return \"N/A(1)\"\n",
        "        \n",
        "    print(\"\\nBest model set found on train set:\")\n",
        "    print()\n",
        "    print(f\"\\tbest parameters={model.best_params_}\")\n",
        "    print(f\"\\tbest '{model.scoring}' score={model.best_score_}\")\n",
        "    print(f\"\\tbest index={model.best_index_}\")\n",
        "    print()\n",
        "    print(f\"Best estimator CTOR:\")\n",
        "    print(f\"\\t{model.best_estimator_}\")\n",
        "    print()\n",
        "    try:\n",
        "        print(f\"Grid scores ('{model.scoring}') on development set:\")\n",
        "        means = model.cv_results_['mean_test_score']\n",
        "        stds  = model.cv_results_['std_test_score']\n",
        "        i=0\n",
        "        for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
        "            print(\"\\t[%2d]: %0.3f (+/-%0.03f) for %r\" % (i, mean, std * 2, params))\n",
        "            i += 1\n",
        "    except:\n",
        "        print(\"WARNING: the random search do not provide means/stds\")\n",
        "    \n",
        "    global currmode                \n",
        "    assert \"f1_micro\"==str(model.scoring), f\"come on, we need to fix the scoring to be able to compare model-fits! Your scoreing={str(model.scoring)}...remember to add scoring='f1_micro' to the search\"   \n",
        "    return f\"best: dat={currmode}, score={model.best_score_:0.5f}, model={GetBestModelCTOR(model.estimator,model.best_params_)}\", model.best_estimator_ \n",
        "\n",
        "def ClassificationReport(model, X_test, y_test, target_names=None):\n",
        "    assert X_test.shape[0]==y_test.shape[0]\n",
        "    print(\"\\nDetailed classification report:\")\n",
        "    print(\"\\tThe model is trained on the full development set.\")\n",
        "    print(\"\\tThe scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, model.predict(X_test)                 \n",
        "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
        "    print()\n",
        "    \n",
        "def FullReport(model, X_test, y_test, t):\n",
        "    print(f\"SEARCH TIME: {t:0.2f} sec\")\n",
        "    beststr, bestmodel = SearchReport(model)\n",
        "    ClassificationReport(model, X_test, y_test)    \n",
        "    print(f\"CTOR for best model: {bestmodel}\\n\")\n",
        "    print(f\"{beststr}\\n\")\n",
        "    return beststr, bestmodel\n",
        "    \n",
        "# def LoadAndSetupData(mode, test_size=0.3):\n",
        "#     assert test_size>=0.0 and test_size<=1.0\n",
        "    \n",
        "#     def ShapeToString(Z):\n",
        "#         n = Z.ndim\n",
        "#         s = \"(\"\n",
        "#         for i in range(n):\n",
        "#             s += f\"{Z.shape[i]:5d}\"\n",
        "#             if i+1!=n:\n",
        "#                 s += \";\"\n",
        "#         return s+\")\"\n",
        "\n",
        "#     global currmode\n",
        "#     currmode=mode\n",
        "#     print(f\"DATA: {currmode}..\")\n",
        "    \n",
        "#     if mode=='moon':\n",
        "#         X, y = itmaldataloaders.MOON_GetDataSet(n_samples=5000, noise=0.2)\n",
        "#         itmaldataloaders.MOON_Plot(X, y)\n",
        "#     elif mode=='mnist':\n",
        "#         X, y = itmaldataloaders.MNIST_GetDataSet(load_mode=0)\n",
        "#         if X.ndim==3:\n",
        "#             X=np.reshape(X, (X.shape[0], -1))\n",
        "#     elif mode=='iris':\n",
        "#         X, y = itmaldataloaders.IRIS_GetDataSet()\n",
        "#     else:\n",
        "#         raise ValueError(f\"could not load data for that particular mode='{mode}', only 'moon'/'mnist'/'iris' supported\")\n",
        "        \n",
        "#     print(f'  org. data:  X.shape      ={ShapeToString(X)}, y.shape      ={ShapeToString(y)}')\n",
        "\n",
        "#     assert X.ndim==2\n",
        "#     assert X.shape[0]==y.shape[0]\n",
        "#     assert y.ndim==1 or (y.ndim==2 and y.shape[1]==0)    \n",
        "    \n",
        "#     X_train, X_test, y_train, y_test = train_test_split(\n",
        "#         X, y, test_size=test_size, random_state=0, shuffle=True\n",
        "#     )\n",
        "    \n",
        "#     print(f'  train data: X_train.shape={ShapeToString(X_train)}, y_train.shape={ShapeToString(y_train)}')\n",
        "#     print(f'  test data:  X_test.shape ={ShapeToString(X_test)}, y_test.shape ={ShapeToString(y_test)}')\n",
        "#     print()\n",
        "    \n",
        "#     return X_train, X_test, y_train, y_test\n",
        "\n",
        "def TryKerasImport(verbose=True):\n",
        "    \n",
        "    kerasok = True\n",
        "    try:\n",
        "        import keras as keras_try\n",
        "    except:\n",
        "        kerasok = False\n",
        "\n",
        "    tensorflowkerasok = True\n",
        "    try:\n",
        "        import tensorflow.keras as tensorflowkeras_try\n",
        "    except:\n",
        "        tensorflowkerasok = False\n",
        "        \n",
        "    ok = kerasok or tensorflowkerasok\n",
        "    \n",
        "    if not ok and verbose:\n",
        "        if not kerasok:\n",
        "            print(\"WARNING: importing 'keras' failed\", file=sys.stderr)\n",
        "        if not tensorflowkerasok:\n",
        "            print(\"WARNING: importing 'tensorflow.keras' failed\", file=sys.stderr)\n",
        "\n",
        "    return ok\n",
        "    \n",
        "print(f\"OK(function setup\" + (\"\" if TryKerasImport() else \", hope MNIST loads works because it seems you miss the installation of Keras or Tensorflow!\") + \")\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1f40521",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_test:  (200, 512, 512, 3)\n",
            "y_test:  (200,)\n",
            "x_train:  (1800, 512, 512, 3)\n",
            "y_train:  (1800,)\n",
            "Epoch 1/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - accuracy: 0.5322 - loss: 2.1089 - val_accuracy: 0.6850 - val_loss: 0.6503\n",
            "Epoch 2/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 3s/step - accuracy: 0.6695 - loss: 0.6343 - val_accuracy: 0.6600 - val_loss: 0.6350\n",
            "Epoch 3/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 3s/step - accuracy: 0.6936 - loss: 0.6009 - val_accuracy: 0.6800 - val_loss: 0.6031\n",
            "Epoch 4/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 3s/step - accuracy: 0.7589 - loss: 0.4954 - val_accuracy: 0.7600 - val_loss: 0.4887\n",
            "Epoch 5/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 3s/step - accuracy: 0.8520 - loss: 0.3529 - val_accuracy: 0.6750 - val_loss: 0.7139\n",
            "Epoch 6/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 3s/step - accuracy: 0.9463 - loss: 0.1471 - val_accuracy: 0.6850 - val_loss: 0.7455\n",
            "Epoch 7/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 3s/step - accuracy: 0.9813 - loss: 0.0689 - val_accuracy: 0.7450 - val_loss: 0.9615\n",
            "Epoch 8/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 3s/step - accuracy: 0.9948 - loss: 0.0188 - val_accuracy: 0.7050 - val_loss: 0.9256\n",
            "Epoch 9/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 3s/step - accuracy: 0.9944 - loss: 0.0309 - val_accuracy: 0.6100 - val_loss: 1.1621\n",
            "Epoch 10/10\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 3s/step - accuracy: 0.9877 - loss: 0.0347 - val_accuracy: 0.6450 - val_loss: 1.3612\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">984064</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │    <span style=\"color: #00af00; text-decoration-color: #00af00\">62,980,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m510\u001b[0m, \u001b[38;5;34m510\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m255\u001b[0m, \u001b[38;5;34m255\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m984064\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │    \u001b[38;5;34m62,980,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">189,109,637</span> (721.40 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m189,109,637\u001b[0m (721.40 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,036,545</span> (240.47 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m63,036,545\u001b[0m (240.47 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">126,073,092</span> (480.93 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m126,073,092\u001b[0m (480.93 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Træning:\n",
        "print(\"x_test: \", X_test.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "print(\"x_train: \", X_train.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "# Shuffle\n",
        "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
        "X_test, y_test = shuffle(X_test, y_test, random_state=42)\n",
        "\n",
        "# Så bygger vi CNN modellen:\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))  # Binær classification (is / not-is)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy', # forklar det her\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7f78e04",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\morte\\anaconda3\\lib\\site-packages (2.18.0)\n",
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (3.9.2)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in c:\\users\\morte\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\morte\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in c:\\users\\morte\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\morte\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
            "Installing collected packages: tensorflow\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "  Rolling back uninstall of tensorflow\n",
            "  Moving to c:\\users\\morte\\anaconda3\\lib\\site-packages\\tensorflow-2.18.0.dist-info\\\n",
            "   from C:\\Users\\morte\\anaconda3\\Lib\\site-packages\\~ensorflow-2.18.0.dist-info\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\morte\\\\anaconda3\\\\Lib\\\\site-packages\\\\tensorflow\\\\compiler\\\\tf2tensorrt\\\\_pywrap_py_utils.pyd'\n",
            "Consider using the `--user` option or check the permissions.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model...\n",
            "\n",
            "Epoch 1/30\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 4s/step - accuracy: 0.5454 - loss: 1.3397 - precision: 0.5315 - recall: 0.4835 - val_accuracy: 0.7550 - val_loss: 0.5967 - val_precision: 0.7742 - val_recall: 0.7200\n",
            "Epoch 2/30\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 3s/step - accuracy: 0.7036 - loss: 0.5848 - precision: 0.7353 - recall: 0.6568 - val_accuracy: 0.7650 - val_loss: 0.5714 - val_precision: 0.7912 - val_recall: 0.7200\n",
            "Epoch 3/30\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 4s/step - accuracy: 0.7190 - loss: 0.5586 - precision: 0.7315 - recall: 0.7165 - val_accuracy: 0.7800 - val_loss: 0.5508 - val_precision: 0.7456 - val_recall: 0.8500\n",
            "Epoch 4/30\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 3s/step - accuracy: 0.7264 - loss: 0.5338 - precision: 0.7165 - recall: 0.7408 - val_accuracy: 0.7950 - val_loss: 0.5480 - val_precision: 0.7864 - val_recall: 0.8100\n",
            "Epoch 5/30\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 3s/step - accuracy: 0.7269 - loss: 0.5428 - precision: 0.7639 - recall: 0.6803 - val_accuracy: 0.7850 - val_loss: 0.5396 - val_precision: 0.8065 - val_recall: 0.7500\n",
            "Epoch 6/30\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 3s/step - accuracy: 0.7387 - loss: 0.5184 - precision: 0.7686 - recall: 0.6934 - val_accuracy: 0.8200 - val_loss: 0.5058 - val_precision: 0.8265 - val_recall: 0.8100\n",
            "Epoch 7/30\n",
            "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 3s/step - accuracy: 0.7794 - loss: 0.4834 - precision: 0.7909 - recall: 0.7722 - val_accuracy: 0.8100 - val_loss: 0.5092 - val_precision: 0.8039 - val_recall: 0.8200\n",
            "Epoch 8/30\n",
            "\u001b[1m31/57\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m2:04\u001b[0m 5s/step - accuracy: 0.7850 - loss: 0.4593 - precision: 0.7689 - recall: 0.7877"
          ]
        }
      ],
      "source": [
        "# !pip install scikeras\n",
        "# !pip install --upgrade keras\n",
        "# !pip install --upgrade tensorflow\n",
        "!pip list "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10897a37",
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'float8_e4m3b11fnuz' from 'tensorflow.python.framework.dtypes' (c:\\Users\\morte\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m time\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Flatten, Dense\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\morte\\anaconda3\\Lib\\site-packages\\tensorflow\\__init__.py:55\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bitwise\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
            "File \u001b[1;32mc:\\Users\\morte\\anaconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\compat\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.compat namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v1\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v2\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m forward_compatibility_horizon \u001b[38;5;66;03m# line: 125\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\morte\\anaconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\__init__.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bitwise\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n",
            "File \u001b[1;32mc:\\Users\\morte\\anaconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.compat namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v1\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m v2\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m forward_compatibility_horizon \u001b[38;5;66;03m# line: 125\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\morte\\anaconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\compat\\v1\\__init__.py:36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributions\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtypes\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m errors\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n",
            "File \u001b[1;32mc:\\Users\\morte\\anaconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\dtypes\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.dtypes namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen_string_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m as_string \u001b[38;5;66;03m# line: 29\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DType \u001b[38;5;66;03m# line: 51\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\morte\\anaconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\compat\\v1\\dtypes\\experimental\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.dtypes.experimental namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m float8_e4m3b11fnuz \u001b[38;5;66;03m# line: 465\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m float8_e4m3fn \u001b[38;5;66;03m# line: 439\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m float8_e4m3fnuz \u001b[38;5;66;03m# line: 452\u001b[39;00m\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'float8_e4m3b11fnuz' from 'tensorflow.python.framework.dtypes' (c:\\Users\\morte\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py)"
          ]
        }
      ],
      "source": [
        "# from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from time import time\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import tensorflow as tf\n",
        "\n",
        "# IMG_SIZE = 512\n",
        "\n",
        "# def build_model(activation='relu'):\n",
        "#     model = Sequential([\n",
        "#         Conv2D(32, (3, 3), activation=activation, input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "#         MaxPooling2D((2, 2)),\n",
        "#         Conv2D(64, (3, 3), activation=activation),\n",
        "#         MaxPooling2D((2, 2)),\n",
        "#         Conv2D(64, (3, 3), activation=activation),\n",
        "#         Flatten(),\n",
        "#         Dense(64, activation=activation),\n",
        "#         Dense(1, activation='sigmoid')  \n",
        "#     ])\n",
        "#     return model\n",
        "\n",
        "# def build_model(activation='relu'):\n",
        "#     model = Sequential([\n",
        "#         Conv2D(32, (3, 3), activation=activation, input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "#         MaxPooling2D((2, 2)),\n",
        "#         Conv2D(64, (3, 3), activation=activation),\n",
        "#         MaxPooling2D((2, 2)),\n",
        "#         Conv2D(64, (3, 3), activation=activation),\n",
        "#         Flatten(),\n",
        "#         Dense(64, activation=activation),\n",
        "#         Dense(1, activation='sigmoid')\n",
        "#     ])\n",
        "#     return model  \n",
        "\n",
        "# param_grid = {\n",
        "#     \"batch_size\": [16, 32],\n",
        "#     \"epochs\": [5, 10],\n",
        "#     \"model__optimizer\": ['adam', 'sgd'],\n",
        "#     \"model__activation\": ['relu', 'tanh']\n",
        "# }\n",
        "\n",
        "# random_tuned = RandomizedSearchCV(\n",
        "#     # estimator=keras_clf,\n",
        "#     param_distributions=param_grid,\n",
        "#     n_iter=5,\n",
        "#     scoring='accuracy',\n",
        "#     cv=3,\n",
        "#     verbose=1,\n",
        "#     random_state=42\n",
        "# )\n",
        "\n",
        "# start = time()\n",
        "# random_tuned.fit(X_train, y_train)  \n",
        "# t = time() - start\n",
        "\n",
        "# y_pred = random_tuned.predict(X_test)\n",
        "# print(\"\\n--- Classification Report ---\")\n",
        "# print(classification_report(y_test, y_pred))\n",
        "# print(\"\\n--- Confusion Matrix ---\")\n",
        "# print(confusion_matrix(y_test, y_pred))\n",
        "# print(f\"\\nBest Parameters: {random_tuned.best_params_}\")\n",
        "# print(f\"Search took {t:.2f} seconds.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
